{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd68be19",
   "metadata": {},
   "source": [
    "**Social Media Addiction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b423632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8103618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- DATA INGESTION --------------------\n",
    "def data_ingestion():\n",
    "    df = pd.read_csv(r'C:\\SocialMediaAddiction_Analysis\\data\\raw\\Social_Media_Addiction.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_ingestion()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5813ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Student_ID','Relationship_Status'], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6040e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- ADDICTION LEVEL --------------------\n",
    "def addiction_lavel(score):\n",
    "    if score <= 3:\n",
    "        return \"Low\"\n",
    "    elif score <= 6:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ab928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- DATA EXPLORATION --------------------\n",
    "def data_exploration(df):\n",
    "\n",
    "    numerical_col = df.select_dtypes(exclude='object').columns\n",
    "    categorical_col = df.select_dtypes(include = 'object').columns\n",
    "\n",
    "    numerical_stats = []\n",
    "    categorical_stats = []\n",
    "\n",
    "   # ---------- Numerical Analysis ----------\n",
    "    Q1 = df[numerical_col].quantile(0.25)\n",
    "    Q3 = df[numerical_col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    LW = Q1 - 1.5 * IQR\n",
    "    UW = Q3 + 1.5 * IQR\n",
    "    outlier_count = ((df[numerical_col] < LW) | (df[numerical_col] > UW))\n",
    "\n",
    "\n",
    "    for col in numerical_col:\n",
    "        num_stats = ({\n",
    "            \"feature\": col,\n",
    "            \"mean\": df[col].mean(),\n",
    "            \"median\": df[col].median(),\n",
    "            \"quartile_1\": Q1[col],\n",
    "            \"quartile_3\": Q3[col],\n",
    "            \"IQR\": IQR[col],\n",
    "            \"lower_whisker\": LW[col],\n",
    "            \"upper_whisker\": UW[col],\n",
    "            \"outlier_count\": outlier_count[col].sum(),\n",
    "            \"std_dev\": df[col].std(),\n",
    "            \"variance\": df[col].var(),\n",
    "            \"skewness\": df[col].skew(),\n",
    "            \"kurtosis\": df[col].kurtosis()\n",
    "        })\n",
    "\n",
    "        numerical_stats.append(num_stats)\n",
    "\n",
    "    # ---------- Categorical Analysis ----------\n",
    "\n",
    "    for col in categorical_col:\n",
    "        cat_stats = ({\n",
    "            \"feature\": col,\n",
    "            \"unique_values\": df[col].nunique(),\n",
    "            \"mode\": df[col].mode()[0] if not df[col].mode().empty else None,\n",
    "            \"missing_values\": df[col].isnull().sum()\n",
    "        })\n",
    "\n",
    "        categorical_stats.append(cat_stats)\n",
    "\n",
    "    # return both reports\n",
    "    numerical_report = pd.DataFrame(numerical_stats)\n",
    "    categorical_report = pd.DataFrame(categorical_stats)\n",
    "\n",
    "    return numerical_report, categorical_col    \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c636019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- PREPROCESSOR --------------------\n",
    "def data_preprocessor(df):\n",
    "\n",
    "    categorical_col = df.select_dtypes(include='object').columns\n",
    "    numerical_col = df.select_dtypes(exclude='object').columns\n",
    "\n",
    "    numerical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numerical_pipeline, numerical_col),\n",
    "        (\"cat\", categorical_pipeline, categorical_col)\n",
    "    ])\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b027b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- MODEL BUILD --------------------\n",
    "def model_build(df):\n",
    "\n",
    "    X = df.drop(columns=[\"Addicted\", \"addiction_lavel\"], errors='ignore')\n",
    "    y = df[\"Addicted\"]\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=1, test_size=0.2\n",
    "    )\n",
    "\n",
    "   # Preprocessing (handle categorical + scaling)\n",
    "    preprocessor = data_preprocessor(X_train)\n",
    "\n",
    "    X_train = preprocessor.fit_transform(X_train)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False)\n",
    "    }\n",
    "\n",
    "    return models, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441975ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- MODEL EVALUATION --------------------\n",
    "def model_evalution(models, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        print(f\"\\n===== {model_name} ===\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda723a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e62522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- MAIN FUNCTION --------------------\n",
    "def main():\n",
    "\n",
    "    # 1 Data Ingestion\n",
    "    df = data_ingestion()\n",
    "\n",
    "    # Create 'addiction_lavel' and 'Addicted' columns (moved from global scope)\n",
    "    df[\"addiction_lavel\"] = df[\"Addicted_Score\"].apply(addiction_lavel)\n",
    "    df[\"Addicted\"] = df[\"addiction_lavel\"].apply(lambda x:1 if x in [\"Medium\",\"High\"] else 0)\n",
    "\n",
    "    # 3 Data Exploration\n",
    "    report = data_exploration(df)\n",
    "    print(report)\n",
    "\n",
    "    # 4 Model Build\n",
    "    models, X_train, X_test, y_train, y_test = model_build(df)\n",
    "\n",
    "    # 5 Model Evaluation\n",
    "    model_evalution(models, X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socialmediaaddiction-analysis (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
