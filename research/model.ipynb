{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd68be19",
   "metadata": {},
   "source": [
    "**Social Media Addiction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b423632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8103618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- DATA INGESTION --------------------\n",
    "def data_ingestion():\n",
    "    df = pd.read_csv(r'C:\\SocialMediaAddiction_Analysis\\data\\raw\\Social_Media_Addiction.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5813ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    \"Student_ID\",\n",
    "    \"Addicted_Score\",        # remove\n",
    "    \"Avg_Daily_Usage_Hours\"  # remove (because target created from it)\n",
    "]\n",
    "\n",
    "df = df.drop(columns=drop_cols, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f6040e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- ADDICTION LEVEL --------------------\n",
    "def addiction_lavel(score):\n",
    "    if score <= 3:\n",
    "        return \"Low\"\n",
    "    elif score <= 6:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"High\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "377ab928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- DATA EXPLORATION --------------------\n",
    "def data_exploration(df):\n",
    "\n",
    "    numerical_col = df.select_dtypes(exclude='object').columns\n",
    "    stats = []\n",
    "\n",
    "    for i in numerical_col:\n",
    "        Q1 = df[i].quantile(0.25)\n",
    "        Q3 = df[i].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        LW = Q1 - 1.5 * IQR\n",
    "        UW = Q3 + 1.5 * IQR\n",
    "\n",
    "        outlier_flag = \"Has Outliers\" if df[(df[i] < LW) | (df[i] > UW)].shape[0] > 0 else \"No Outliers\"\n",
    "\n",
    "        stats.append({\n",
    "            \"Feature\": i,\n",
    "            \"Minimum\": df[i].min(),\n",
    "            \"Maximum\": df[i].max(),\n",
    "            \"Mean\": df[i].mean(),\n",
    "            \"Median\": df[i].median(),\n",
    "            \"IQR\": IQR,\n",
    "            \"Std\": df[i].std(),\n",
    "            \"Skewness\": df[i].skew(),\n",
    "            \"Kurtosis\": df[i].kurt(),\n",
    "            \"Outliers\": outlier_flag\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7c636019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- PREPROCESSOR --------------------\n",
    "def data_preprocessor(df):\n",
    "\n",
    "    categorical_col = df.select_dtypes(include='object').columns\n",
    "    numerical_col = df.select_dtypes(exclude='object').columns\n",
    "\n",
    "    numerical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numerical_pipeline, numerical_col),\n",
    "        (\"cat\", categorical_pipeline, categorical_col)\n",
    "    ])\n",
    "\n",
    "    return preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b027b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- MODEL BUILD --------------------\n",
    "def model_build(df):\n",
    "\n",
    "    X = df.drop(columns=[\"Addicted\", \"addiction_lavel\"], errors='ignore')\n",
    "    y = df[\"Addicted\"]\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=1, test_size=0.2\n",
    "    )\n",
    "\n",
    "   # Preprocessing (handle categorical + scaling)\n",
    "    preprocessor = data_preprocessor(X_train)\n",
    "\n",
    "    X_train = preprocessor.fit_transform(X_train)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False)\n",
    "    }\n",
    "\n",
    "    return models, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "441975ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- MODEL EVALUATION --------------------\n",
    "def model_evalution(models, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        print(f\"\\n===== {model_name} ===\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f5e62522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Feature  Minimum  Maximum        Mean  Median    IQR  \\\n",
      "0                   Student_ID      1.0    705.0  353.000000   353.0  352.0   \n",
      "1                          Age     18.0     24.0   20.659574    21.0    3.0   \n",
      "2        Avg_Daily_Usage_Hours      1.5      8.5    4.918723     4.8    1.7   \n",
      "3        Sleep_Hours_Per_Night      3.8      9.6    6.868936     6.9    1.7   \n",
      "4          Mental_Health_Score      4.0      9.0    6.226950     6.0    2.0   \n",
      "5  Conflicts_Over_Social_Media      0.0      5.0    2.849645     3.0    2.0   \n",
      "6               Addicted_Score      2.0      9.0    6.436879     7.0    3.0   \n",
      "7                     Addicted      0.0      1.0    0.975887     1.0    0.0   \n",
      "\n",
      "          Std  Skewness   Kurtosis      Outliers  \n",
      "0  203.660256  0.000000  -1.200000   No Outliers  \n",
      "1    1.399217  0.368909  -0.507844   No Outliers  \n",
      "2    1.257395  0.164634  -0.352554  Has Outliers  \n",
      "3    1.126848 -0.109040  -0.519811   No Outliers  \n",
      "4    1.105055  0.049023  -0.835574   No Outliers  \n",
      "5    0.957968 -0.162340  -0.383374   No Outliers  \n",
      "6    1.587165 -0.296828  -0.894483   No Outliers  \n",
      "7    0.153510 -6.217695  36.764017  Has Outliers  \n",
      "\n",
      "===== Logistic Regression ===\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00       137\n",
      "\n",
      "    accuracy                           1.00       141\n",
      "   macro avg       1.00      1.00      1.00       141\n",
      "weighted avg       1.00      1.00      1.00       141\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  4   0]\n",
      " [  0 137]]\n",
      "--------------------------------------------------\n",
      "\n",
      "===== Random Forest ===\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00       137\n",
      "\n",
      "    accuracy                           1.00       141\n",
      "   macro avg       1.00      1.00      1.00       141\n",
      "weighted avg       1.00      1.00      1.00       141\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  4   0]\n",
      " [  0 137]]\n",
      "--------------------------------------------------\n",
      "\n",
      "===== Gradient Boosting ===\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00       137\n",
      "\n",
      "    accuracy                           1.00       141\n",
      "   macro avg       1.00      1.00      1.00       141\n",
      "weighted avg       1.00      1.00      1.00       141\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  4   0]\n",
      " [  0 137]]\n",
      "--------------------------------------------------\n",
      "\n",
      "===== XGBoost ===\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00       137\n",
      "\n",
      "    accuracy                           1.00       141\n",
      "   macro avg       1.00      1.00      1.00       141\n",
      "weighted avg       1.00      1.00      1.00       141\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  4   0]\n",
      " [  0 137]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SocialMediaAddiction_Analysis\\.venv\\Lib\\site-packages\\xgboost\\training.py:200: UserWarning: [21:10:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:782: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# -------------------- MAIN FUNCTION --------------------\n",
    "def main():\n",
    "\n",
    "    # 1 Data Ingestion\n",
    "    df = data_ingestion()\n",
    "\n",
    "    # Create 'addiction_lavel' and 'Addicted' columns (moved from global scope)\n",
    "    df[\"addiction_lavel\"] = df[\"Addicted_Score\"].apply(addiction_lavel)\n",
    "    df[\"Addicted\"] = df[\"addiction_lavel\"].apply(lambda x:1 if x in [\"Medium\",\"High\"] else 0)\n",
    "\n",
    "    # 3 Data Exploration\n",
    "    report = data_exploration(df)\n",
    "    print(report)\n",
    "\n",
    "    # 4 Model Build\n",
    "    models, X_train, X_test, y_train, y_test = model_build(df)\n",
    "\n",
    "    # 5 Model Evaluation\n",
    "    model_evalution(models, X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "socialmediaaddiction-analysis (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
